{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"tumor-data-without-healthy.xlsx\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "labels = [value for column, value in data.iloc[0].items()]\n",
    "data = data.set_axis(labels, axis=1)\n",
    "data = data[data.columns[1:]].apply(\n",
    "    lambda x: pd.to_numeric(x.replace('<', '').replace(',', '.'), errors='coerce')\n",
    ")\n",
    "data.drop(index=0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "data[\"Гормональная активность 0-нет               1-да\"] = data[\n",
    "    \"Гормональная активность 0-нет               1-да\"].astype(str)\n",
    "data[\"Гормональная активность 0-нет               1-да\"] = data[\n",
    "\"Гормональная активность 0-нет               1-да\"].fillna(\"missing\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "\"\"\" dropping some columns \"\"\"\n",
    "\n",
    "data.dropna(axis=1, how=\"all\", inplace=True)\n",
    "data.dropna(axis=0, thresh=int(data.shape[1] * 0.6), inplace=True)\n",
    "data.dropna(axis=1, thresh=int(data.shape[0] * 0.6), inplace=True)\n",
    "data.drop([\"Пол:    0-жен, 1-муж\"], inplace=True, axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "X = data.drop(columns=[\"КАН\", \"АКР\"])\n",
    "y = np.argmax(data[[\"КАН\", \"АКР\"]], axis=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.9, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-22 14:20:44,743] A new study created in memory with name: no-name-7420c1ea-9643-4159-9fa5-b43de17ac9dc\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:44,777] Trial 0 finished with value: 0.9090909090909091 and parameters: {'C': 86.30376378357053, 'max_iter': 710, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:44,842] Trial 1 finished with value: 0.9090909090909091 and parameters: {'C': 0.056136943443333434, 'max_iter': 1515, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:44,853] Trial 2 finished with value: 0.9090909090909091 and parameters: {'C': 388.5951768835664, 'max_iter': 1001, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:44,862] Trial 3 finished with value: 0.9090909090909091 and parameters: {'C': 0.00014776767342647128, 'max_iter': 348, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:44,873] Trial 4 finished with value: 0.9090909090909091 and parameters: {'C': 1155.0103532266678, 'max_iter': 945, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:44,888] Trial 5 finished with value: 0.9090909090909091 and parameters: {'C': 9042.360693470306, 'max_iter': 1944, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2024-12-22 14:20:44,931] Trial 6 finished with value: 0.9090909090909091 and parameters: {'C': 0.00472718672201436, 'max_iter': 486, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:44,988] Trial 7 finished with value: 0.9090909090909091 and parameters: {'C': 0.011280626907954937, 'max_iter': 1482, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:45,006] Trial 8 finished with value: 0.9090909090909091 and parameters: {'C': 0.0024205609224846117, 'max_iter': 308, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,031] Trial 9 finished with value: 0.9090909090909091 and parameters: {'C': 46.891367309567684, 'max_iter': 1819, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:45,069] Trial 10 finished with value: 0.9090909090909091 and parameters: {'C': 13.555931842720497, 'max_iter': 703, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,130] Trial 11 finished with value: 0.9090909090909091 and parameters: {'C': 0.5905230596034199, 'max_iter': 1428, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:45,188] Trial 12 finished with value: 0.9090909090909091 and parameters: {'C': 0.3776689312324538, 'max_iter': 1343, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:45,261] Trial 13 finished with value: 0.9090909090909091 and parameters: {'C': 6.01478154265665, 'max_iter': 1637, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,286] Trial 14 finished with value: 0.9090909090909091 and parameters: {'C': 82608.95705440911, 'max_iter': 1137, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,353] Trial 15 finished with value: 0.9090909090909091 and parameters: {'C': 2.3243038326649947e-05, 'max_iter': 699, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:45,396] Trial 16 finished with value: 0.9090909090909091 and parameters: {'C': 0.08565151839992263, 'max_iter': 819, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,462] Trial 17 finished with value: 0.9090909090909091 and parameters: {'C': 0.04347926851692484, 'max_iter': 1251, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:45,535] Trial 18 finished with value: 0.9090909090909091 and parameters: {'C': 129.70113840850883, 'max_iter': 1709, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,555] Trial 19 finished with value: 0.9090909090909091 and parameters: {'C': 3.5165893818871763, 'max_iter': 1109, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:45,590] Trial 20 finished with value: 0.9090909090909091 and parameters: {'C': 0.0006197110417398557, 'max_iter': 534, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,609] Trial 21 finished with value: 0.9090909090909091 and parameters: {'C': 514.0422236160797, 'max_iter': 996, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,629] Trial 22 finished with value: 0.9090909090909091 and parameters: {'C': 2455.9303915743963, 'max_iter': 918, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,651] Trial 23 finished with value: 0.9090909090909091 and parameters: {'C': 60.063278979476166, 'max_iter': 1568, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,670] Trial 24 finished with value: 0.9090909090909091 and parameters: {'C': 9683.05256394398, 'max_iter': 1278, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,690] Trial 25 finished with value: 0.9090909090909091 and parameters: {'C': 1.6955951232404827, 'max_iter': 710, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,717] Trial 26 finished with value: 0.9090909090909091 and parameters: {'C': 285.56621931475667, 'max_iter': 1060, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,738] Trial 27 finished with value: 0.9090909090909091 and parameters: {'C': 23.40616575991262, 'max_iter': 839, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 0 with value: 0.9090909090909091.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:45,773] Trial 28 finished with value: 0.9090909090909091 and parameters: {'C': 0.21766872489216885, 'max_iter': 556, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 0 with value: 0.9090909090909091.\n",
      "[I 2024-12-22 14:20:45,796] Trial 29 finished with value: 1.0 and parameters: {'C': 97196.77664830638, 'max_iter': 432, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:45,819] Trial 30 finished with value: 0.9090909090909091 and parameters: {'C': 12128.48687399003, 'max_iter': 430, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:45,843] Trial 31 finished with value: 1.0 and parameters: {'C': 2960.3908263096964, 'max_iter': 602, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:45,867] Trial 32 finished with value: 0.9090909090909091 and parameters: {'C': 99309.35936745453, 'max_iter': 570, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:45,891] Trial 33 finished with value: 1.0 and parameters: {'C': 4128.998157136505, 'max_iter': 420, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:45,916] Trial 34 finished with value: 1.0 and parameters: {'C': 2380.2581555032407, 'max_iter': 380, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:45,942] Trial 35 finished with value: 0.9090909090909091 and parameters: {'C': 3336.747010631389, 'max_iter': 440, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:45,966] Trial 36 finished with value: 0.9090909090909091 and parameters: {'C': 32183.33631819105, 'max_iter': 372, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:45,990] Trial 37 finished with value: 0.9090909090909091 and parameters: {'C': 1828.0217692601311, 'max_iter': 619, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,014] Trial 38 finished with value: 1.0 and parameters: {'C': 36915.629151855894, 'max_iter': 312, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,041] Trial 39 finished with value: 1.0 and parameters: {'C': 941.9497592169321, 'max_iter': 406, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,064] Trial 40 finished with value: 1.0 and parameters: {'C': 6398.237536159941, 'max_iter': 636, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,088] Trial 41 finished with value: 1.0 and parameters: {'C': 23187.007001216265, 'max_iter': 322, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,114] Trial 42 finished with value: 1.0 and parameters: {'C': 32947.33124923327, 'max_iter': 466, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,141] Trial 43 finished with value: 0.9090909090909091 and parameters: {'C': 233.1920696244096, 'max_iter': 333, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,164] Trial 44 finished with value: 1.0 and parameters: {'C': 6708.66994608054, 'max_iter': 499, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,189] Trial 45 finished with value: 0.9090909090909091 and parameters: {'C': 46434.84568980551, 'max_iter': 784, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,215] Trial 46 finished with value: 1.0 and parameters: {'C': 1082.5754988372494, 'max_iter': 308, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,240] Trial 47 finished with value: 1.0 and parameters: {'C': 19101.18871823866, 'max_iter': 641, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,264] Trial 48 finished with value: 1.0 and parameters: {'C': 4356.395593504162, 'max_iter': 392, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,287] Trial 49 finished with value: 0.9090909090909091 and parameters: {'C': 590.5440858664758, 'max_iter': 494, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,313] Trial 50 finished with value: 1.0 and parameters: {'C': 86297.03739651566, 'max_iter': 580, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,341] Trial 51 finished with value: 1.0 and parameters: {'C': 829.8213062463739, 'max_iter': 407, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,365] Trial 52 finished with value: 1.0 and parameters: {'C': 1854.8504976536096, 'max_iter': 384, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,390] Trial 53 finished with value: 1.0 and parameters: {'C': 11939.593084057673, 'max_iter': 456, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,415] Trial 54 finished with value: 1.0 and parameters: {'C': 4074.041959072993, 'max_iter': 300, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,443] Trial 55 finished with value: 0.9090909090909091 and parameters: {'C': 134.19326180926413, 'max_iter': 510, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,468] Trial 56 finished with value: 0.9090909090909091 and parameters: {'C': 35454.601638717555, 'max_iter': 704, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,510] Trial 57 finished with value: 0.9090909090909091 and parameters: {'C': 29.08898627064901, 'max_iter': 1988, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,537] Trial 58 finished with value: 1.0 and parameters: {'C': 1090.5947829049117, 'max_iter': 376, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,565] Trial 59 finished with value: 1.0 and parameters: {'C': 347.56655642153754, 'max_iter': 764, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,590] Trial 60 finished with value: 1.0 and parameters: {'C': 14774.293399858303, 'max_iter': 438, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,614] Trial 61 finished with value: 1.0 and parameters: {'C': 6221.291475077291, 'max_iter': 631, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,641] Trial 62 finished with value: 0.9090909090909091 and parameters: {'C': 50949.674702073804, 'max_iter': 545, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,666] Trial 63 finished with value: 0.9090909090909091 and parameters: {'C': 5983.948558112304, 'max_iter': 605, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,692] Trial 64 finished with value: 1.0 and parameters: {'C': 3110.089496128582, 'max_iter': 668, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:46,742] Trial 65 finished with value: 0.9090909090909091 and parameters: {'C': 13645.414029579166, 'max_iter': 909, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,769] Trial 66 finished with value: 1.0 and parameters: {'C': 1763.4545698369202, 'max_iter': 357, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,803] Trial 67 finished with value: 0.9090909090909091 and parameters: {'C': 99.62023475350156, 'max_iter': 504, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,849] Trial 68 finished with value: 0.9090909090909091 and parameters: {'C': 10.391209908406303, 'max_iter': 422, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,879] Trial 69 finished with value: 0.9090909090909091 and parameters: {'C': 99110.43703777519, 'max_iter': 570, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:46,913] Trial 70 finished with value: 0.9090909090909091 and parameters: {'C': 8236.037301957726, 'max_iter': 460, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,938] Trial 71 finished with value: 1.0 and parameters: {'C': 21800.036504661795, 'max_iter': 336, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,963] Trial 72 finished with value: 1.0 and parameters: {'C': 25316.03471641564, 'max_iter': 301, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:46,989] Trial 73 finished with value: 0.9090909090909091 and parameters: {'C': 44752.143641875664, 'max_iter': 365, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,015] Trial 74 finished with value: 1.0 and parameters: {'C': 2779.010593062911, 'max_iter': 532, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,034] Trial 75 finished with value: 0.9090909090909091 and parameters: {'C': 2.612601520609409e-05, 'max_iter': 410, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,061] Trial 76 finished with value: 1.0 and parameters: {'C': 555.1545716828408, 'max_iter': 353, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,094] Trial 77 finished with value: 0.9090909090909091 and parameters: {'C': 180.21259870131934, 'max_iter': 460, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,122] Trial 78 finished with value: 1.0 and parameters: {'C': 17890.458768014345, 'max_iter': 665, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,196] Trial 79 finished with value: 0.9090909090909091 and parameters: {'C': 0.0074798874084266815, 'max_iter': 743, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,223] Trial 80 finished with value: 0.9090909090909091 and parameters: {'C': 48544.75753087021, 'max_iter': 489, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,251] Trial 81 finished with value: 0.9090909090909091 and parameters: {'C': 7976.149011963769, 'max_iter': 407, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,278] Trial 82 finished with value: 1.0 and parameters: {'C': 27758.00341991332, 'max_iter': 466, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,304] Trial 83 finished with value: 1.0 and parameters: {'C': 1864.7560264469896, 'max_iter': 332, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,329] Trial 84 finished with value: 0.9090909090909091 and parameters: {'C': 63747.110792969484, 'max_iter': 534, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,355] Trial 85 finished with value: 0.9090909090909091 and parameters: {'C': 4073.5797735715114, 'max_iter': 584, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,374] Trial 86 finished with value: 0.9090909090909091 and parameters: {'C': 11821.113567657872, 'max_iter': 1190, 'solver': 'liblinear', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,400] Trial 87 finished with value: 1.0 and parameters: {'C': 1024.8259299217284, 'max_iter': 389, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "C:\\Users\\arafa\\anaconda3\\envs\\university-projects\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:349: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "[I 2024-12-22 14:20:47,432] Trial 88 finished with value: 0.9090909090909091 and parameters: {'C': 24202.76526777642, 'max_iter': 437, 'solver': 'saga', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,459] Trial 89 finished with value: 1.0 and parameters: {'C': 5372.721167707665, 'max_iter': 340, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,485] Trial 90 finished with value: 0.9090909090909091 and parameters: {'C': 63277.45885463683, 'max_iter': 1819, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,513] Trial 91 finished with value: 1.0 and parameters: {'C': 8988.098149767378, 'max_iter': 493, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,540] Trial 92 finished with value: 0.9090909090909091 and parameters: {'C': 32052.264725719557, 'max_iter': 524, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,569] Trial 93 finished with value: 1.0 and parameters: {'C': 1594.3354679070292, 'max_iter': 476, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,597] Trial 94 finished with value: 1.0 and parameters: {'C': 5349.33776152577, 'max_iter': 853, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,625] Trial 95 finished with value: 1.0 and parameters: {'C': 17497.918761049063, 'max_iter': 608, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,654] Trial 96 finished with value: 0.9090909090909091 and parameters: {'C': 787.9924261170918, 'max_iter': 409, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': True}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,682] Trial 97 finished with value: 1.0 and parameters: {'C': 2798.696485501603, 'max_iter': 309, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,713] Trial 98 finished with value: 0.9090909090909091 and parameters: {'C': 418.45692616951885, 'max_iter': 559, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n",
      "[I 2024-12-22 14:20:47,741] Trial 99 finished with value: 0.9090909090909091 and parameters: {'C': 8229.123014084631, 'max_iter': 1400, 'solver': 'lbfgs', 'penalty': 'l2', 'fit_intercept': False}. Best is trial 29 with value: 1.0.\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        \"C\":trial.suggest_float('C', 1e-5, 1e5, log=True),\n",
    "        \"max_iter\":trial.suggest_int('max_iter', 300, 2000),\n",
    "        \"solver\":trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga']),\n",
    "        \"penalty\":trial.suggest_categorical('penalty', ['l2']),\n",
    "        'fit_intercept' : trial.suggest_categorical('fit_intercept' , [True, False]),\n",
    "    }\n",
    "\n",
    "    model = make_pipeline(\n",
    "        SimpleImputer(strategy=\"median\"),\n",
    "        LogisticRegression(**param, random_state=42)\n",
    "    )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    score = model.score(X_test, y_test)\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "model = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    LogisticRegression(**study.best_params)\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "Accuracy: 0.7894736842105263\n",
      "F1: 0.75\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "\n",
      "Fold 1:\n",
      "Accuracy: 0.7777777777777778\n",
      "F1: 0.75\n",
      "Precision: 0.75\n",
      "Recall: 0.75\n",
      "\n",
      "Fold 2:\n",
      "Accuracy: 0.8333333333333334\n",
      "F1: 0.8235294117647058\n",
      "Precision: 0.7777777777777778\n",
      "Recall: 0.875\n",
      "\n",
      "Fold 3:\n",
      "Accuracy: 0.7777777777777778\n",
      "F1: 0.6666666666666666\n",
      "Precision: 1.0\n",
      "Recall: 0.5\n",
      "\n",
      "Fold 4:\n",
      "Accuracy: 0.8888888888888888\n",
      "F1: 0.875\n",
      "Precision: 0.875\n",
      "Recall: 0.875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X_train, y_train)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    xtrain, xtest = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "    ytrain, ytest = y_train[train_index], y_train[test_index]\n",
    "    model.fit(xtrain, ytrain)\n",
    "\n",
    "    y_pred = model.predict(xtest)\n",
    "\n",
    "    print(\"Accuracy:\", accuracy_score(ytest, y_pred))\n",
    "    print(\"F1:\", f1_score(ytest, y_pred))\n",
    "    print(\"Precision:\", precision_score(ytest, y_pred))\n",
    "    print(\"Recall:\", recall_score(ytest, y_pred))\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline(steps=[('simpleimputer', SimpleImputer(strategy='median')),\n                ('logisticregression',\n                 LogisticRegression(C=97196.77664830638, fit_intercept=False,\n                                    max_iter=432))])",
      "text/html": "<style>#sk-container-id-3 {\n  /* Definition of color scheme common for light and dark mode */\n  --sklearn-color-text: black;\n  --sklearn-color-line: gray;\n  /* Definition of color scheme for unfitted estimators */\n  --sklearn-color-unfitted-level-0: #fff5e6;\n  --sklearn-color-unfitted-level-1: #f6e4d2;\n  --sklearn-color-unfitted-level-2: #ffe0b3;\n  --sklearn-color-unfitted-level-3: chocolate;\n  /* Definition of color scheme for fitted estimators */\n  --sklearn-color-fitted-level-0: #f0f8ff;\n  --sklearn-color-fitted-level-1: #d4ebff;\n  --sklearn-color-fitted-level-2: #b3dbfd;\n  --sklearn-color-fitted-level-3: cornflowerblue;\n\n  /* Specific color for light theme */\n  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n  --sklearn-color-icon: #696969;\n\n  @media (prefers-color-scheme: dark) {\n    /* Redefinition of color scheme for dark theme */\n    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n    --sklearn-color-icon: #878787;\n  }\n}\n\n#sk-container-id-3 {\n  color: var(--sklearn-color-text);\n}\n\n#sk-container-id-3 pre {\n  padding: 0;\n}\n\n#sk-container-id-3 input.sk-hidden--visually {\n  border: 0;\n  clip: rect(1px 1px 1px 1px);\n  clip: rect(1px, 1px, 1px, 1px);\n  height: 1px;\n  margin: -1px;\n  overflow: hidden;\n  padding: 0;\n  position: absolute;\n  width: 1px;\n}\n\n#sk-container-id-3 div.sk-dashed-wrapped {\n  border: 1px dashed var(--sklearn-color-line);\n  margin: 0 0.4em 0.5em 0.4em;\n  box-sizing: border-box;\n  padding-bottom: 0.4em;\n  background-color: var(--sklearn-color-background);\n}\n\n#sk-container-id-3 div.sk-container {\n  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n     but bootstrap.min.css set `[hidden] { display: none !important; }`\n     so we also need the `!important` here to be able to override the\n     default hidden behavior on the sphinx rendered scikit-learn.org.\n     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n  display: inline-block !important;\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-text-repr-fallback {\n  display: none;\n}\n\ndiv.sk-parallel-item,\ndiv.sk-serial,\ndiv.sk-item {\n  /* draw centered vertical line to link estimators */\n  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n  background-size: 2px 100%;\n  background-repeat: no-repeat;\n  background-position: center center;\n}\n\n/* Parallel-specific style estimator block */\n\n#sk-container-id-3 div.sk-parallel-item::after {\n  content: \"\";\n  width: 100%;\n  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n  flex-grow: 1;\n}\n\n#sk-container-id-3 div.sk-parallel {\n  display: flex;\n  align-items: stretch;\n  justify-content: center;\n  background-color: var(--sklearn-color-background);\n  position: relative;\n}\n\n#sk-container-id-3 div.sk-parallel-item {\n  display: flex;\n  flex-direction: column;\n}\n\n#sk-container-id-3 div.sk-parallel-item:first-child::after {\n  align-self: flex-end;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:last-child::after {\n  align-self: flex-start;\n  width: 50%;\n}\n\n#sk-container-id-3 div.sk-parallel-item:only-child::after {\n  width: 0;\n}\n\n/* Serial-specific style estimator block */\n\n#sk-container-id-3 div.sk-serial {\n  display: flex;\n  flex-direction: column;\n  align-items: center;\n  background-color: var(--sklearn-color-background);\n  padding-right: 1em;\n  padding-left: 1em;\n}\n\n\n/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\nclickable and can be expanded/collapsed.\n- Pipeline and ColumnTransformer use this feature and define the default style\n- Estimators will overwrite some part of the style using the `sk-estimator` class\n*/\n\n/* Pipeline and ColumnTransformer style (default) */\n\n#sk-container-id-3 div.sk-toggleable {\n  /* Default theme specific background. It is overwritten whether we have a\n  specific estimator or a Pipeline/ColumnTransformer */\n  background-color: var(--sklearn-color-background);\n}\n\n/* Toggleable label */\n#sk-container-id-3 label.sk-toggleable__label {\n  cursor: pointer;\n  display: block;\n  width: 100%;\n  margin-bottom: 0;\n  padding: 0.5em;\n  box-sizing: border-box;\n  text-align: center;\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n  /* Arrow on the left of the label */\n  content: \"▸\";\n  float: left;\n  margin-right: 0.25em;\n  color: var(--sklearn-color-icon);\n}\n\n#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n  color: var(--sklearn-color-text);\n}\n\n/* Toggleable content - dropdown */\n\n#sk-container-id-3 div.sk-toggleable__content {\n  max-height: 0;\n  max-width: 0;\n  overflow: hidden;\n  text-align: left;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content pre {\n  margin: 0.2em;\n  border-radius: 0.25em;\n  color: var(--sklearn-color-text);\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n  /* unfitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n  /* Expand drop-down */\n  max-height: 200px;\n  max-width: 100%;\n  overflow: auto;\n}\n\n#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n  content: \"▾\";\n}\n\n/* Pipeline/ColumnTransformer-specific style */\n\n#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator-specific style */\n\n/* Colorize estimator box */\n#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n#sk-container-id-3 div.sk-label label {\n  /* The background is the default theme color */\n  color: var(--sklearn-color-text-on-default-background);\n}\n\n/* On hover, darken the color of the background */\n#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n/* Label box, darken color on hover, fitted */\n#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n  color: var(--sklearn-color-text);\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Estimator label */\n\n#sk-container-id-3 div.sk-label label {\n  font-family: monospace;\n  font-weight: bold;\n  display: inline-block;\n  line-height: 1.2em;\n}\n\n#sk-container-id-3 div.sk-label-container {\n  text-align: center;\n}\n\n/* Estimator-specific */\n#sk-container-id-3 div.sk-estimator {\n  font-family: monospace;\n  border: 1px dotted var(--sklearn-color-border-box);\n  border-radius: 0.25em;\n  box-sizing: border-box;\n  margin-bottom: 0.5em;\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-0);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-0);\n}\n\n/* on hover */\n#sk-container-id-3 div.sk-estimator:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-2);\n}\n\n#sk-container-id-3 div.sk-estimator.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-2);\n}\n\n/* Specification for estimator info (e.g. \"i\" and \"?\") */\n\n/* Common style for \"i\" and \"?\" */\n\n.sk-estimator-doc-link,\na:link.sk-estimator-doc-link,\na:visited.sk-estimator-doc-link {\n  float: right;\n  font-size: smaller;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1em;\n  height: 1em;\n  width: 1em;\n  text-decoration: none !important;\n  margin-left: 1ex;\n  /* unfitted */\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n  color: var(--sklearn-color-unfitted-level-1);\n}\n\n.sk-estimator-doc-link.fitted,\na:link.sk-estimator-doc-link.fitted,\na:visited.sk-estimator-doc-link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\ndiv.sk-estimator:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link:hover,\n.sk-estimator-doc-link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\ndiv.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover,\ndiv.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n.sk-estimator-doc-link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n/* Span, style for the box shown on hovering the info icon */\n.sk-estimator-doc-link span {\n  display: none;\n  z-index: 9999;\n  position: relative;\n  font-weight: normal;\n  right: .2ex;\n  padding: .5ex;\n  margin: .5ex;\n  width: min-content;\n  min-width: 20ex;\n  max-width: 50ex;\n  color: var(--sklearn-color-text);\n  box-shadow: 2pt 2pt 4pt #999;\n  /* unfitted */\n  background: var(--sklearn-color-unfitted-level-0);\n  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n}\n\n.sk-estimator-doc-link.fitted span {\n  /* fitted */\n  background: var(--sklearn-color-fitted-level-0);\n  border: var(--sklearn-color-fitted-level-3);\n}\n\n.sk-estimator-doc-link:hover span {\n  display: block;\n}\n\n/* \"?\"-specific style due to the `<a>` HTML tag */\n\n#sk-container-id-3 a.estimator_doc_link {\n  float: right;\n  font-size: 1rem;\n  line-height: 1em;\n  font-family: monospace;\n  background-color: var(--sklearn-color-background);\n  border-radius: 1rem;\n  height: 1rem;\n  width: 1rem;\n  text-decoration: none;\n  /* unfitted */\n  color: var(--sklearn-color-unfitted-level-1);\n  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted {\n  /* fitted */\n  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n  color: var(--sklearn-color-fitted-level-1);\n}\n\n/* On hover */\n#sk-container-id-3 a.estimator_doc_link:hover {\n  /* unfitted */\n  background-color: var(--sklearn-color-unfitted-level-3);\n  color: var(--sklearn-color-background);\n  text-decoration: none;\n}\n\n#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n  /* fitted */\n  background-color: var(--sklearn-color-fitted-level-3);\n}\n</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n                (&#x27;logisticregression&#x27;,\n                 LogisticRegression(C=97196.77664830638, fit_intercept=False,\n                                    max_iter=432))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;simpleimputer&#x27;, SimpleImputer(strategy=&#x27;median&#x27;)),\n                (&#x27;logisticregression&#x27;,\n                 LogisticRegression(C=97196.77664830638, fit_intercept=False,\n                                    max_iter=432))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=97196.77664830638, fit_intercept=False, max_iter=432)</pre></div> </div></div></div></div></div></div>"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "cv = cross_validate(model, X, y, n_jobs=-1,\n",
    "                    scoring=[\"accuracy\",\n",
    "                             \"f1\",\n",
    "                             \"precision\",\n",
    "                             \"recall\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " accuracy 0.9523809523809523 \n",
      " f1 0.9473684210526315 \n",
      " recall 0.9 \n",
      " precision 1.0 \n",
      "\n",
      "---------------------------------------------\n",
      " accuracy 0.8095238095238095 \n",
      " f1 0.75 \n",
      " recall 0.6 \n",
      " precision 1.0 \n",
      "\n",
      "---------------------------------------------\n",
      " accuracy 0.7 \n",
      " f1 0.7 \n",
      " recall 0.7777777777777778 \n",
      " precision 0.6363636363636364 \n",
      "\n",
      "---------------------------------------------\n",
      " accuracy 0.8 \n",
      " f1 0.75 \n",
      " recall 0.6666666666666666 \n",
      " precision 0.8571428571428571 \n",
      "\n",
      "---------------------------------------------\n",
      " accuracy 0.7 \n",
      " f1 0.7 \n",
      " recall 0.7777777777777778 \n",
      " precision 0.6363636363636364 \n",
      "\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cv)-1):\n",
    "    print(\n",
    "        \" accuracy\", cv[\"test_accuracy\"][i], \"\\n\",\n",
    "        \"f1\", cv[\"test_f1\"][i], \"\\n\",\n",
    "        \"recall\", cv[\"test_recall\"][i], \"\\n\",\n",
    "        \"precision\", cv[\"test_precision\"][i], \"\\n\"\n",
    "    )\n",
    "    print(\"---------------------------------------------\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00         7\n",
      "\n",
      "    accuracy                           1.00        11\n",
      "   macro avg       1.00      1.00      1.00        11\n",
      "weighted avg       1.00      1.00      1.00        11\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "data": {
      "text/plain": "                                              Feature  Importance\n15                                            dA2_17B    0.410032\n32                                                THS    0.323919\n28                                           16dP2_3A    0.277667\n17                                          16DHEA-3a    0.239710\n10                  свободный кортизон мочи (ВЭЖХ)       0.234860\n44                                                HHB    0.206659\n35                                            alloTHB    0.187273\n14                                                 Et    0.167964\n27                                             dP3_3А    0.146995\n40                                                bCN    0.126973\n2                             Нативная плотность, НU     0.113454\n6     Кортизол после пробы с 1 мг дексаметазона (ДМТ)    0.105551\n18                                          16DHEA-3b    0.068251\n1                             Максимальный размер, мм    0.057135\n33                                                THE    0.053123\n23                                                 A3    0.050419\n21                                               11An    0.037564\n24                                                 P2    0.034497\n5                                Кортизол крови вечер    0.033165\n3                                               Weiss    0.012765\n8                                          ДГЭА-С        0.006201\n47                                            THB_THA    0.005087\n12  Индекс свободный кортизон/свободный кортизол в...    0.001105\n49                                            THF_THE    0.000525\n48                                           THF_THE1    0.000259\n43                                           THF/THE2    0.000043\n51                                           aTHB_THB   -0.000776\n0    Гормональная активность 0-нет               1-да   -0.000892\n9                    свободный кортизол мочи (ВЭЖХ)     -0.000915\n45                                              An|Et   -0.001132\n50                                           aTHF_THF   -0.001359\n52                                          11An_11Et   -0.001454\n34                                                THB   -0.004146\n46                                             THE_P3   -0.008521\n36                                                THF   -0.016264\n7                                         АКТГ  утром   -0.018978\n4                                 Кортизол крови утро   -0.022099\n22                                               11Et   -0.032476\n26                                                dP2   -0.046642\n42                                            alloTHE   -0.058268\n16                                               DHEA   -0.059787\n38                                                THA   -0.064468\n20                                             17-ОНP   -0.070899\n11            18 гидроксикортикостерон мочи (ВЭЖХ)      -0.074033\n29                                                dA3   -0.109194\n31                                            11oxoP3   -0.122958\n25                                                 P3   -0.135208\n41                                                 CL   -0.167683\n13                                                 An   -0.193933\n53                                            THE_THS   -0.222703\n37                                            alloTHF   -0.226477\n54                                        THE_11oxoP3   -0.238682\n39                                                aCN   -0.249485\n19                                            11охоET   -0.306891\n30                                            11oxoP2   -0.482399",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Feature</th>\n      <th>Importance</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15</th>\n      <td>dA2_17B</td>\n      <td>0.410032</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>THS</td>\n      <td>0.323919</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>16dP2_3A</td>\n      <td>0.277667</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>16DHEA-3a</td>\n      <td>0.239710</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>свободный кортизон мочи (ВЭЖХ)</td>\n      <td>0.234860</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>HHB</td>\n      <td>0.206659</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>alloTHB</td>\n      <td>0.187273</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Et</td>\n      <td>0.167964</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>dP3_3А</td>\n      <td>0.146995</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>bCN</td>\n      <td>0.126973</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Нативная плотность, НU</td>\n      <td>0.113454</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Кортизол после пробы с 1 мг дексаметазона (ДМТ)</td>\n      <td>0.105551</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>16DHEA-3b</td>\n      <td>0.068251</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Максимальный размер, мм</td>\n      <td>0.057135</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>THE</td>\n      <td>0.053123</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>A3</td>\n      <td>0.050419</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>11An</td>\n      <td>0.037564</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>P2</td>\n      <td>0.034497</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Кортизол крови вечер</td>\n      <td>0.033165</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Weiss</td>\n      <td>0.012765</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>ДГЭА-С</td>\n      <td>0.006201</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>THB_THA</td>\n      <td>0.005087</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Индекс свободный кортизон/свободный кортизол в...</td>\n      <td>0.001105</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>THF_THE</td>\n      <td>0.000525</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>THF_THE1</td>\n      <td>0.000259</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>THF/THE2</td>\n      <td>0.000043</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>aTHB_THB</td>\n      <td>-0.000776</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Гормональная активность 0-нет               1-да</td>\n      <td>-0.000892</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>свободный кортизол мочи (ВЭЖХ)</td>\n      <td>-0.000915</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>An|Et</td>\n      <td>-0.001132</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>aTHF_THF</td>\n      <td>-0.001359</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>11An_11Et</td>\n      <td>-0.001454</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>THB</td>\n      <td>-0.004146</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>THE_P3</td>\n      <td>-0.008521</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>THF</td>\n      <td>-0.016264</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>АКТГ  утром</td>\n      <td>-0.018978</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Кортизол крови утро</td>\n      <td>-0.022099</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>11Et</td>\n      <td>-0.032476</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>dP2</td>\n      <td>-0.046642</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>alloTHE</td>\n      <td>-0.058268</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>DHEA</td>\n      <td>-0.059787</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>THA</td>\n      <td>-0.064468</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>17-ОНP</td>\n      <td>-0.070899</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>18 гидроксикортикостерон мочи (ВЭЖХ)</td>\n      <td>-0.074033</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>dA3</td>\n      <td>-0.109194</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>11oxoP3</td>\n      <td>-0.122958</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>P3</td>\n      <td>-0.135208</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>CL</td>\n      <td>-0.167683</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>An</td>\n      <td>-0.193933</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>THE_THS</td>\n      <td>-0.222703</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>alloTHF</td>\n      <td>-0.226477</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>THE_11oxoP3</td>\n      <td>-0.238682</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>aCN</td>\n      <td>-0.249485</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>11охоET</td>\n      <td>-0.306891</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>11oxoP2</td>\n      <td>-0.482399</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = model[\"logisticregression\"]\n",
    "\n",
    "feature_importances = lr.coef_.T.reshape(55,)\n",
    "feature_names = X.columns\n",
    "\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "importance_df"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
